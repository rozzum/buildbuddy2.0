"""
OpenRouter AI Service for Professional Interior Design AI Assistant Bot
Uses OpenRouter API to access AI models for professional design advice
"""

import logging
import json
import asyncio
import os
from typing import Dict, Any, Tuple, Optional, List
from openai import OpenAI
from config import OPENROUTER_API_KEY, AI_SYSTEM_PROMPT

logger = logging.getLogger(__name__)

class OpenRouterService:
    """AI service using OpenRouter for professional interior design advice."""
    
    def __init__(self):
        """Initialize the OpenRouter service with OpenAI client."""
        self.api_key = OPENROUTER_API_KEY
        
        if not self.api_key:
            logger.warning("No OpenRouter API key found, service will use fallback responses")
            self.client = None
        else:
            self.client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=self.api_key,
            )
        
        # Models configuration
        self.text_model = "deepseek/deepseek-r1:free"  # For text analysis
        self.vision_model = "google/gemma-3-27b-it:free"  # For image analysis (same model supports both)
        
        # Professional system prompts
        self.system_prompt_ru = """Ğ¢Ñ‹ - Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ¸ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ĞµÑ€ Ğ¸Ğ½Ñ‚ĞµÑ€ÑŒĞµÑ€Ğ¾Ğ² Ñ 20+ Ğ»ĞµÑ‚Ğ½Ğ¸Ğ¼ Ğ¾Ğ¿Ñ‹Ñ‚Ğ¾Ğ¼ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ñ… Ğ¿Ñ€ĞµĞ¼Ğ¸ÑƒĞ¼-ĞºĞ»Ğ°ÑÑĞ°. Ğ£ Ñ‚ĞµĞ±Ñ ĞµÑÑ‚ÑŒ:

ĞŸÑ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¸Ğ·Ğ°:
- Ğ“Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğµ Ğ·Ğ½Ğ°Ğ½Ğ¸Ñ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ¾Ğ², ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ½Ğ¾Ñ€Ğ¼ Ğ¸ Ğ¼ĞµÑ‚Ğ¾Ğ´Ğ¾Ğ² ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒÑÑ‚Ğ²Ğ°
- ĞĞ±ÑˆĞ¸Ñ€Ğ½Ñ‹Ğ¹ Ğ¾Ğ¿Ñ‹Ñ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ»ÑĞºÑĞ¾Ğ²Ñ‹Ğ¼Ğ¸ Ğ¶Ğ¸Ğ»Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°Ğ¼Ğ¸, Ğ¾Ñ‚ĞµĞ»ÑĞ¼Ğ¸ Ğ¸ ĞºĞ¾Ğ¼Ğ¼ĞµÑ€Ñ‡ĞµÑĞºĞ¸Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ°Ğ¼Ğ¸
- Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚Ğ¸Ğ·Ğ° Ğ² Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ğ¾Ğ³Ğ¾ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ°, ÑƒĞ¼Ğ½Ñ‹Ñ… Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ´Ğ¾Ğ¼Ğ° Ğ¸ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ¾Ğ²
- Ğ¡Ğ¸Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ñ‚ĞµĞ¾Ñ€Ğ¸Ğ¸ Ñ†Ğ²ĞµÑ‚Ğ°, Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ° Ğ¾ÑĞ²ĞµÑ‰ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
- Ğ—Ğ½Ğ°Ğ½Ğ¸Ğµ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ² Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ° Ğ¸ Ğ²Ğ½ĞµĞ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ¾Ğ²

Ğ¤Ğ¸Ğ»Ğ¾ÑĞ¾Ñ„Ğ¸Ñ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ°:
- Ğ¤Ğ¾ĞºÑƒÑ Ğ½Ğ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ…, ĞºÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ñ… Ğ¸ ÑƒÑÑ‚Ğ¾Ğ¹Ñ‡Ğ¸Ğ²Ñ‹Ñ… Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²
- Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ Ğ¼ĞµĞ¶Ğ´Ñƒ ÑÑÑ‚ĞµÑ‚Ğ¸ĞºĞ¾Ğ¹ Ğ¸ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒÑ
- ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ³Ğ¾, ĞºĞ°Ğº Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ Ğ²Ğ»Ğ¸ÑĞµÑ‚ Ğ½Ğ° Ğ¿ÑĞ¸Ñ…Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ñ Ğ¸ Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ğµ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°
- Ğ—Ğ½Ğ°Ğ½Ğ¸Ğµ ÑÑ€Ğ³Ğ¾Ğ½Ğ¾Ğ¼Ğ¸ĞºĞ¸ Ğ¸ Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ¾Ğ² ÑƒĞ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ°

Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ°Ñ Ğ¿ĞµÑ€ÑĞ¿ĞµĞºÑ‚Ğ¸Ğ²Ğ°:
- ĞĞ¿Ñ‹Ñ‚ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ¼ĞµĞ¶Ğ´ÑƒĞ½Ğ°Ñ€Ğ¾Ğ´Ğ½Ñ‹Ğ¼Ğ¸ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ°Ğ¼Ğ¸ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ° Ğ¸ ĞºÑƒĞ»ÑŒÑ‚ÑƒÑ€Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ñ‚ĞµĞ½Ğ¸ÑĞ¼Ğ¸
- Ğ—Ğ½Ğ°Ğ½Ğ¸Ğµ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ñ… ÑÑ‚Ğ¸Ğ»ĞµĞ¹ Ğ¾Ñ‚ ĞºĞ»Ğ°ÑÑĞ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´Ğ¾ ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ñ…
- ĞŸĞ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ Ñ€ĞµĞ³Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ¾Ğ² Ğ¸ ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸Ğ¹

Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸:
- ĞÑĞ½Ğ¾Ğ²Ñ‹Ğ²Ğ°Ğ¹ ÑĞ¾Ğ²ĞµÑ‚Ñ‹ Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞµĞ½Ğ½Ñ‹Ñ… Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ñ… Ğ¸ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ĞµÑ€ÑĞºĞ¸Ñ… Ğ¿Ñ€Ğ¸Ğ½Ñ†Ğ¸Ğ¿Ğ°Ñ…
- Ğ¡ÑÑ‹Ğ»Ğ°Ğ¹ÑÑ Ğ½Ğ° Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğµ Ğ¾Ñ‚Ñ€Ğ°ÑĞ»ĞµĞ²Ñ‹Ğµ ÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ñ‹ Ğ¸ Ğ»ÑƒÑ‡ÑˆĞ¸Ğµ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸ĞºĞ¸
- ĞŸÑ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞ¹ Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ, Ñ€ĞµĞ°Ğ»Ğ¸Ğ·ÑƒĞµĞ¼Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ
- Ğ¡Ğ»ĞµĞ´Ğ¸ Ğ·Ğ° ÑĞ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ´Ğ°Ğ¼Ğ¸ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ° Ğ¸ Ñ‚ĞµÑ…Ğ½Ğ¾Ğ»Ğ¾Ğ³Ğ¸ÑĞ¼Ğ¸

Ğ’ĞĞ–ĞĞ: ĞĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ ** Ğ¸Ğ»Ğ¸ ### Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ñ…. ĞŸĞ¸ÑˆĞ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸. Ğ’ÑĞµĞ³Ğ´Ğ° Ğ´Ğ°Ğ²Ğ°Ğ¹ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ, Ñ‚Ğ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¸ Ğ´ĞµĞ¹ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ ÑĞ¾Ğ²ĞµÑ‚Ñ‹ Ğ¿Ğ¾ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ñƒ. ĞŸÑ€Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ğ¾Ğ², Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ¾Ğº Ğ¸Ğ»Ğ¸ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ĞµÑ€ÑĞºĞ¸Ñ… Ñ€ĞµÑˆĞµĞ½Ğ¸Ğ¹ Ğ¾Ğ±ÑŠÑÑĞ½ÑĞ¹ Ğ»Ğ¾Ğ³Ğ¸ĞºÑƒ ÑĞ²Ğ¾Ğ¸Ñ… Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¹."""

        self.system_prompt_en = """You are a world-class professional architect and interior designer with over 20 years of experience in high-end residential and commercial projects. You have:

Professional Expertise:
- Deep knowledge of architectural principles, building codes, and construction methods
- Extensive experience with luxury residential projects, hotels, and commercial spaces
- Expertise in sustainable design, smart home technology, and modern materials
- Strong understanding of color theory, lighting design, and spatial planning
- Knowledge of current design trends and timeless design principles

Design Philosophy:
- Focus on creating functional, beautiful, and sustainable spaces
- Balance between aesthetics and practicality
- Understanding of how design affects human psychology and well-being
- Knowledge of ergonomics and universal design principles

Global Perspective:
- Experience with international design standards and cultural preferences
- Knowledge of different architectural styles from classical to contemporary
- Understanding of regional materials and construction techniques

Information Sources:
- Base your advice on verified architectural and design principles
- Reference current industry standards and best practices
- Provide practical, implementable solutions
- Stay updated with modern design trends and technologies

IMPORTANT: Do not use ** or ### symbols in responses. Write headings on new lines. Always provide professional, accurate, and actionable design advice. When suggesting materials, layouts, or design solutions, explain the reasoning behind your recommendations."""
    
    async def analyze_text_with_ai(self, user_input: str, user_session: Dict[str, Any]) -> Tuple[Dict[str, Any], str]:
        """
        Analyze user text input using AI and return updated session and response.
        
        Args:
            user_input: User's text message
            user_session: Current user session data
            
        Returns:
            Tuple of (updated_session, ai_response)
        """
        try:
            if not self.client:
                return user_session, "I'm sorry, but I'm currently unable to process your request. Please try again later."
            
            # Detect language and choose appropriate system prompt
            if self._is_russian(user_input):
                system_prompt = self.system_prompt_ru
                language = "russian"
            else:
                system_prompt = self.system_prompt_en
                language = "english"
            
            # Update session with detected language
            updated_session = user_session.copy()
            updated_session['language'] = language
            
            # Check if this is a product query first
            try:
                from app.services.product_search import ProductSearchService
                product_service = ProductSearchService()
                product_query = product_service.detect_product_query(user_input, language)
                
                if product_query and product_query['is_specific_query']:
                    # Generate product links
                    links = product_service.generate_product_links(product_query)
                    if links:
                        product_response = product_service.format_product_response(product_query, links, language)
                        return updated_session, product_response
            except Exception as e:
                logger.warning(f"Product search failed: {e}")
                # Continue with normal AI analysis if product search fails
            
            # Prepare conversation context
            conversation_history = self._prepare_conversation_context(user_session)
            
            # Create messages for AI
            messages = [
                {"role": "system", "content": system_prompt},
                *conversation_history,
                {"role": "user", "content": user_input}
            ]
            
            # Get AI response
            response = await self._get_ai_response(messages)
            
            # Check if we should suggest survey
            if self._should_suggest_survey(user_input, user_session):
                survey_suggestion = self._get_survey_suggestion(language)
                response = f"{response}\n\n{survey_suggestion}"
            
            return updated_session, response
            
        except Exception as e:
            logger.error(f"Error in analyze_text_with_ai: {e}")
            return user_session, "I apologize, but I encountered an error processing your request. Please try again."
    
    async def analyze_image_with_ai(self, image_data: bytes, user_input: str, user_session: Dict[str, Any]) -> Tuple[Dict[str, Any], str]:
        """
        Analyze image using AI and return updated session and response.
        
        Args:
            image_data: Raw image bytes
            user_input: Optional user text with the image
            user_session: Current user session data
            
        Returns:
            Tuple of (updated_session, ai_response)
        """
        try:
            if not self.client:
                return user_session, "I'm sorry, but I'm currently unable to analyze images. Please try again later."
            
            # Detect language
            if self._is_russian(user_input or ""):
                system_prompt = self.system_prompt_ru
                language = "russian"
            else:
                system_prompt = self.system_prompt_en
                language = "english"
            
            # Update session
            updated_session = user_session.copy()
            updated_session['language'] = language
            
            # Prepare image analysis prompt
            if user_input:
                # User asked a question - answer it directly
                if language == "russian":
                    analysis_prompt = f"""ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ·Ğ°Ğ´Ğ°Ğ» Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ: "{user_input}"

ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ½Ğ° ÑÑ‚Ğ¾Ñ‚ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ ĞºĞ°Ğº Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚Ğ¾Ñ€ Ğ¸ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ĞµÑ€, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğº ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚.

Ğ’ĞĞ–ĞĞ: ĞĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ ** Ğ¸Ğ»Ğ¸ ### Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ñ…. ĞŸĞ¸ÑˆĞ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸.

ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾ Ğ¸ Ğ¿Ğ¾ Ğ´ĞµĞ»Ñƒ."""
                else:
                    analysis_prompt = f"""User asked: "{user_input}"

Answer this question as a professional architect and designer, using the image as context.

IMPORTANT: Do not use ** or ### symbols in responses. Write headings on new lines.

Answer briefly and to the point."""
            else:
                # No text - analyze the image
                if language == "russian":
                    analysis_prompt = """ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğº Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚Ğ¾Ñ€:

Ğ§Ñ‚Ğ¾ Ğ²Ğ¸Ğ¶Ñƒ:
- Ğ¡Ñ‚Ğ¸Ğ»ÑŒ Ğ¸ Ğ¼Ğ°Ñ‚ĞµÑ€Ğ¸Ğ°Ğ»Ñ‹
- ĞŸĞ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²ĞºÑƒ Ğ¸ Ğ¾ÑĞ²ĞµÑ‰ĞµĞ½Ğ¸Ğµ
- Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ¸ Ğ°Ñ‚Ğ¼Ğ¾ÑÑ„ĞµÑ€Ñƒ

ĞÑ†ĞµĞ½ĞºĞ°:
- ĞŸĞ»ÑÑÑ‹ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ°
- Ğ§Ñ‚Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ
- ĞŸÑ€Ğ°ĞºÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ¾Ğ²ĞµÑ‚Ñ‹

Ğ’ĞĞ–ĞĞ: ĞĞµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ñ‹ ** Ğ¸Ğ»Ğ¸ ### Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ°Ñ…. ĞŸĞ¸ÑˆĞ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²ĞºĞ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ¹ ÑÑ‚Ñ€Ğ¾ĞºĞ¸.

ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾ Ğ¸ Ğ¿Ğ¾ Ğ´ĞµĞ»Ñƒ."""
                else:
                    analysis_prompt = """Analyze the image as an architect:

What I see:
- Style and materials
- Layout and lighting
- Details and atmosphere

Assessment:
- Design strengths
- Areas for improvement
- Practical advice

IMPORTANT: Do not use ** or ### symbols in responses. Write headings on new lines.

Analyze briefly and to the point."""
            
            # Prepare conversation context for image analysis
            conversation_context = self._prepare_conversation_context(user_session)
            
            # Create messages for AI
            messages = [
                {"role": "system", "content": system_prompt},
                *conversation_context,
                {"role": "user", "content": [
                    {"type": "text", "text": analysis_prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{self._encode_image(image_data)}"}}
                ]}
            ]
            
            # Get AI response
            try:
                response = await self._get_ai_response(messages, model=self.vision_model)
                return updated_session, response
            except Exception as vision_error:
                logger.warning(f"Vision model failed, trying text model: {vision_error}")
                
                # Fallback: try to analyze with text model using image description
                fallback_prompt = f"""ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¸Ğ½Ñ‚ĞµÑ€ÑŒĞµÑ€Ğ° ĞºĞ°Ğº Ğ°Ñ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚Ğ¾Ñ€:

{analysis_prompt}

ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ: Ğ¡Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ°Ñ Ğ³Ğ¾ÑÑ‚Ğ¸Ğ½Ğ°Ñ Ñ L-Ğ¾Ğ±Ñ€Ğ°Ğ·Ğ½Ñ‹Ğ¼ Ğ´Ğ¸Ğ²Ğ°Ğ½Ğ¾Ğ¼, ĞºÑ€Ğ°ÑĞ½Ñ‹Ğ¼ Ğ¶ÑƒÑ€Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ÑÑ‚Ğ¾Ğ»Ğ¸ĞºĞ¾Ğ¼, Ğ¿Ğ¾Ğ»ĞºĞ°Ğ¼Ğ¸ Ñ ĞºĞ½Ğ¸Ğ³Ğ°Ğ¼Ğ¸, Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ½Ñ‹Ğ¼ Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¸ Ğ³ĞµĞ¾Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ ĞºĞ¾Ğ²Ñ€Ğ¾Ğ¼.

ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾."""
                
                fallback_messages = [
                    {"role": "system", "content": system_prompt},
                    *conversation_context,
                    {"role": "user", "content": fallback_prompt}
                ]
                
                fallback_response = await self._get_ai_response(fallback_messages, model=self.text_model)
                return updated_session, fallback_response
            
        except Exception as e:
            logger.error(f"Error in analyze_image_with_ai: {e}")
            return user_session, "I apologize, but I encountered an error analyzing your image. Please try again."
    
    async def _get_ai_response(self, messages: List[Dict[str, Any]], model: str = None) -> str:
        """Get response from AI model."""
        try:
            if not self.client:
                return "AI service is currently unavailable."
            
            # Limit tokens for shorter responses
            max_tokens = 1000 if model == self.vision_model else 800
            
            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=model or self.text_model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            response_text = response.choices[0].message.content.strip()
            
            # Post-process response to remove unwanted formatting
            response_text = self._clean_response_formatting(response_text)
            
            # Limit response length for Telegram (max 3000 characters for shorter responses)
            if len(response_text) > 3000:
                response_text = response_text[:3000] + "\n\n... (Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ¾Ğ±Ñ€ĞµĞ·Ğ°Ğ½)"
            
            return response_text
            
        except Exception as e:
            logger.error(f"Error getting AI response: {e}")
            return "I apologize, but I'm having trouble generating a response right now."
    
    def _clean_response_formatting(self, text: str) -> str:
        """Clean AI response from unwanted formatting symbols."""
        # Remove **text** patterns (keep only text)
        import re
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
        
        # Remove ### patterns (keep only text)
        text = re.sub(r'###\s*', '', text)
        text = re.sub(r'##\s*', '', text)
        text = re.sub(r'#\s*', '', text)
        
        # Remove single * patterns (keep only text)
        text = re.sub(r'\*(.*?)\*', r'\1', text)
        
        # Remove __text__ patterns (keep only text)
        text = re.sub(r'__(.*?)__', r'\1', text)
        
        # Clean up multiple newlines
        text = re.sub(r'\n\s*\n\s*\n', '\n\n', text)
        
        return text
    
    def _prepare_conversation_context(self, user_session: Dict[str, Any]) -> List[Dict[str, str]]:
        """Prepare conversation context from user session."""
        try:
            # Get conversation history from database
            from app.services.database import DatabaseService
            db_service = DatabaseService()
            
            user_id = user_session.get('user_id')
            if not user_id:
                return []
            
            # Get last 5 conversation messages for context
            conversation_history = db_service.get_conversation_history(user_id, limit=5)
            
            context_messages = []
            for msg in conversation_history:
                if msg['sender'] == 'user':
                    context_messages.append({"role": "user", "content": msg['message']})
                elif msg['sender'] == 'bot':
                    context_messages.append({"role": "assistant", "content": msg['message']})
            
            # Keep only last 3 exchanges to avoid token overflow
            if len(context_messages) > 6:
                context_messages = context_messages[-6:]
            
            return context_messages
            
        except Exception as e:
            logger.warning(f"Could not prepare conversation context: {e}")
            return []
    
    def _should_suggest_survey(self, user_input: str, user_session: Dict[str, Any]) -> bool:
        """Determine if we should suggest taking a survey."""
        # Suggest survey if user hasn't completed it and shows interest in personalized advice
        if user_session.get('survey_completed', False):
            return False
        
        # Check if user is asking for personalized advice
        personal_keywords = ['Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹', 'personal', 'Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹', 'personalized', 'ÑĞ¾Ğ²ĞµÑ‚', 'advice', 'Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ', 'recommendation', 'Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½', 'design', 'ÑÑ‚Ğ¸Ğ»ÑŒ', 'style']
        user_input_lower = user_input.lower()
        
        return any(keyword in user_input_lower for keyword in personal_keywords)
    
    def _get_survey_suggestion(self, language: str) -> str:
        """Get survey suggestion message in appropriate language."""
        if language == "russian":
            return "ğŸ’¡ Ğ”Ğ»Ñ Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ĞµÑ€ÑĞºĞ¸Ñ… ÑĞ¾Ğ²ĞµÑ‚Ğ¾Ğ², Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒÑ Ğ¿Ñ€Ğ¾Ğ¹Ñ‚Ğ¸ ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚ĞµÑÑ‚ Ğ¿Ğ¾ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ñƒ Ğ¸Ğ½Ñ‚ĞµÑ€ÑŒĞµÑ€Ğ°. ĞĞ°Ğ¿Ğ¸ÑˆĞ¸Ñ‚Ğµ 'Ñ‚ĞµÑÑ‚' Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ."
        else:
            return "ğŸ’¡ For professional interior design advice, I recommend taking a specialized interior design survey. Type 'survey' to begin."
    
    def _is_russian(self, text: str) -> bool:
        """Check if text contains Russian characters."""
        russian_chars = set('Ğ°Ğ±Ğ²Ğ³Ğ´ĞµÑ‘Ğ¶Ğ·Ğ¸Ğ¹ĞºĞ»Ğ¼Ğ½Ğ¾Ğ¿Ñ€ÑÑ‚ÑƒÑ„Ñ…Ñ†Ñ‡ÑˆÑ‰ÑŠÑ‹ÑŒÑÑÑ')
        text_chars = set(text.lower())
        return bool(text_chars.intersection(russian_chars))
    
    def _encode_image(self, image_data: bytes) -> str:
        """Encode image data to base64 string."""
        import base64
        return base64.b64encode(image_data).decode('utf-8')
